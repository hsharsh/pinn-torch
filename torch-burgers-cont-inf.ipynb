{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "sys.path.append('utils_continuous')\n",
    "from utils_continuous import preprocess_data_continuous_inference, plot_results_continuous_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess it\n",
    "data_path = 'data/burgers_shock.mat'\n",
    "\n",
    "Nu = 100\n",
    "Nf = 10000\n",
    "\n",
    "x, t, u_exact, X, T, lb, ub, train_X_u, train_u, train_X_f, test_X, test_u = preprocess_data_continuous_inference(data_path, Nu, Nf)\n",
    "train_X_u = torch.tensor(train_X_u, dtype = torch.float, requires_grad = True, device = device)\n",
    "train_u = torch.tensor(train_u, dtype = torch.float, requires_grad = True, device = device)\n",
    "train_X_f = torch.tensor(train_X_f, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_X = torch.tensor(test_X, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_u = torch.tensor(test_u, dtype = torch.float, requires_grad = True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, lb, ub):\n",
    "        super().__init__()\n",
    "        self.lb = torch.tensor(lb, dtype = torch.float, device = device)\n",
    "        self.ub = torch.tensor(ub, dtype = torch.float, device = device)\n",
    "        \n",
    "        # Layer module\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Make the neural network\n",
    "        input_dim = layers[0]\n",
    "        for output_dim in layers[1:]:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "            nn.init.xavier_normal_(self.layers[-1].weight)\n",
    "            input_dim = output_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.tanh(layer(x))\n",
    "\n",
    "        outputs = self.layers[-1](x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, X_f, lb, ub, nu, layers = [2, 20, 20, 20, 1], lr = 1e-2, device = torch.device('cpu')):\n",
    "        self.nu = nu\n",
    "        self.x_f = X_f[:, :1]\n",
    "        self.t_f = X_f[:, 1:]\n",
    "        \n",
    "        self.net_u = NeuralNet(layers, lb, ub)\n",
    "        self.net_u.to(device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.net_u.parameters(), lr = lr, betas=(0.9, 0.999))\n",
    "    \n",
    "    def net_f(self):\n",
    "        \n",
    "        u = self.net_u(torch.cat([self.x_f, self.t_f],1))\n",
    "        \n",
    "        u_temp1 = torch.ones(self.x_f.size(), device = device)\n",
    "        u_temp2 = torch.ones(self.x_f.size(), device = device)\n",
    "        u_temp3 = torch.ones(self.x_f.size(), device = device)\n",
    "        \n",
    "        u_t = grad(u, self.t_f, grad_outputs = u_temp1, create_graph = True)[0]\n",
    "        u_x = grad(u, self.x_f, grad_outputs = u_temp2, create_graph = True)[0]\n",
    "        u_xx = grad(u_x, self.x_f, grad_outputs = u_temp3, create_graph = True)[0]\n",
    "        \n",
    "        f = u_t + u*u_x - (self.nu)*u_xx\n",
    "        \n",
    "        del u_temp1\n",
    "        del u_temp2\n",
    "        del u_temp3\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    def loss_f(self, u, u_pred):\n",
    "        return torch.mean(torch.square(u-u_pred)) + torch.mean(torch.square(self.net_f()))\n",
    "    \n",
    "    def optimizer_step(self, X_u, u):\n",
    "        # Zero the grads for the model paramters in the optimizer\n",
    "        self.optimizer.zero_grad()\n",
    "            \n",
    "        # Compute the losses and backpropagate the losses\n",
    "        loss = self.loss_f(u, self.net_u(X_u))\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer one iteration with the given optimizer\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def fit(self, X_u, u, epochs = 1):\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = self.optimizer_step(X_u, u)\n",
    "\n",
    "            if epoch % 100 == 99:\n",
    "                with torch.no_grad():\n",
    "                    valid_loss = torch.norm(test_u - pinn.predict(test_X), 2)/torch.norm(test_u, 2)\n",
    "                    print(f'Epoch {epoch+1}: Training Loss = {loss_value}, Validation Loss = {valid_loss.item()}')\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        return self.net_u(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "pinn = PINN(train_X_f, lb, ub, nu = (0.01/np.pi), layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1], lr = 0.001, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 0.09432919323444366, Validation Loss = 0.5668474435806274\n",
      "Epoch 200: Training Loss = 0.06752654165029526, Validation Loss = 0.509410560131073\n",
      "Epoch 300: Training Loss = 0.05274968966841698, Validation Loss = 0.4611217677593231\n",
      "Epoch 400: Training Loss = 0.03988169878721237, Validation Loss = 0.39974337816238403\n",
      "Epoch 500: Training Loss = 0.029588177800178528, Validation Loss = 0.32834091782569885\n",
      "Epoch 600: Training Loss = 0.021516047418117523, Validation Loss = 0.2844264805316925\n",
      "Epoch 700: Training Loss = 0.01302124559879303, Validation Loss = 0.2292969673871994\n",
      "Epoch 800: Training Loss = 0.013239944353699684, Validation Loss = 0.4802347719669342\n",
      "Epoch 900: Training Loss = 0.00993889570236206, Validation Loss = 0.48654472827911377\n",
      "Epoch 1000: Training Loss = 0.004674773663282394, Validation Loss = 0.298623651266098\n",
      "Epoch 1100: Training Loss = 0.0036241125781089067, Validation Loss = 0.28950515389442444\n",
      "Epoch 1200: Training Loss = 0.0027265315875411034, Validation Loss = 0.24914133548736572\n",
      "Epoch 1300: Training Loss = 0.0022964742965996265, Validation Loss = 0.2505298852920532\n",
      "Epoch 1400: Training Loss = 0.0015613657888025045, Validation Loss = 0.11273915320634842\n",
      "Epoch 1500: Training Loss = 0.0012521713506430387, Validation Loss = 0.10438287258148193\n",
      "Epoch 1600: Training Loss = 0.0010890676639974117, Validation Loss = 0.10206782817840576\n",
      "Epoch 1700: Training Loss = 0.06526020914316177, Validation Loss = 0.11959671974182129\n",
      "Epoch 1800: Training Loss = 0.0010337824933230877, Validation Loss = 0.0635874792933464\n",
      "Epoch 1900: Training Loss = 0.0008450959576293826, Validation Loss = 0.052613336592912674\n",
      "Epoch 2000: Training Loss = 0.0007739616557955742, Validation Loss = 0.05143015459179878\n",
      "Epoch 2100: Training Loss = 0.0007167517323978245, Validation Loss = 0.05049184337258339\n",
      "Epoch 2200: Training Loss = 0.0006670060101896524, Validation Loss = 0.0495833158493042\n",
      "Epoch 2300: Training Loss = 0.0008769783889874816, Validation Loss = 0.05783332884311676\n",
      "Epoch 2400: Training Loss = 0.0006199530325829983, Validation Loss = 0.0929422453045845\n",
      "Epoch 2500: Training Loss = 0.0005833865725435317, Validation Loss = 0.09153109788894653\n",
      "Epoch 2600: Training Loss = 0.0005512964562512934, Validation Loss = 0.09032734483480453\n",
      "Epoch 2700: Training Loss = 0.0005216802237555385, Validation Loss = 0.08915655314922333\n",
      "Epoch 2800: Training Loss = 0.0007041100179776549, Validation Loss = 0.10421835631132126\n",
      "Epoch 2900: Training Loss = 0.000526494812220335, Validation Loss = 0.10102040320634842\n",
      "Epoch 3000: Training Loss = 0.0004921775544062257, Validation Loss = 0.09546840190887451\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "pinn.fit(train_X_u, train_u, epochs = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09546840190887451\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "u_pred = pinn.predict(test_X)\n",
    "valid_loss = torch.norm(test_u - pinn.predict(test_X), 2)/torch.norm(test_u, 2)\n",
    "print(valid_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7ea8db086547059bae87adee00477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "%matplotlib widget\n",
    "device = torch.device('cpu')\n",
    "\n",
    "plot_results_continuous_inference(x, t, X, T, u_exact, u_pred.to(device).detach().numpy(),\n",
    "                                  train_X_u.to(device).detach().numpy(), train_X_f.to(device).detach().numpy(),\n",
    "                                  train_u.to(device).detach().numpy(), test_X.to(device).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
