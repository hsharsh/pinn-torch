{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "sys.path.append('utils_discrete')\n",
    "from utils_discrete import preprocess_data_discrete_inference, plot_results_discrete_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess it\n",
    "data_path = 'data/burgers_shock.mat'\n",
    "\n",
    "N = 250\n",
    "q = 500\n",
    "noise = 0.0\n",
    "idx_t0 = 10\n",
    "idx_t1 = 90\n",
    "\n",
    "x, t, u_exact, T, lb, ub, dt, x0, u0, x1, test_X, test_u, IRK_weights = preprocess_data_discrete_inference(data_path, idx_t0, idx_t1, q, N, noise)\n",
    "\n",
    "x0 = torch.tensor(x0, dtype = torch.float, requires_grad = True, device = device)\n",
    "u0 = torch.tensor(u0, dtype = torch.float, requires_grad = True, device = device)\n",
    "x1 = torch.tensor(x1, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_X = torch.tensor(test_X, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_u = torch.tensor(test_u, dtype = torch.float, requires_grad = True, device = device)\n",
    "dt = torch.tensor(dt, dtype = torch.float, requires_grad = True, device = device)\n",
    "IRK_weights = torch.tensor(IRK_weights, dtype = torch.float, requires_grad = True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, lb, ub):\n",
    "        super().__init__()\n",
    "        self.lb = torch.tensor(lb, dtype = torch.float, device = device)\n",
    "        self.ub = torch.tensor(ub, dtype = torch.float, device = device)\n",
    "        \n",
    "        # Layer module\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Make the neural network\n",
    "        input_dim = layers[0]\n",
    "        for output_dim in layers[1:]:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "            nn.init.xavier_normal_(self.layers[-1].weight)\n",
    "            input_dim = output_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.tanh(layer(x))\n",
    "\n",
    "        outputs = self.layers[-1](x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, dt, x0, u0, x1, lb, ub, IRK_weights, nu, layers = [2, 20, 20, 20, 1], lr = 1e-2, device = torch.device('cpu')):\n",
    "        self.nu = nu\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.u0 = u0\n",
    "        self.x1 = x1\n",
    "        self.IRK_weights = IRK_weights\n",
    "        \n",
    "        self.net_u = NeuralNet(layers, lb, ub)\n",
    "        self.net_u.to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.net_u.parameters(), lr = lr, betas=(0.9, 0.999))\n",
    "    \n",
    "    def forward_gradients(self, y, x):\n",
    "        # x.shape -> (#data_points x 1) (250 x 1)\n",
    "        # y.shape -> (#data_points x #RK stages) (250 x 500)\n",
    "        temp1 = torch.ones(y.size(), device = device, requires_grad = True)\n",
    "        temp2 = torch.ones(x.size(), device = device)\n",
    "        \n",
    "        g = grad(y, x, grad_outputs = temp1, create_graph = True)[0]\n",
    "        dy = grad(g, temp1, grad_outputs = temp2, create_graph = True)[0]\n",
    "        \n",
    "        del temp1, temp2\n",
    "        \n",
    "        # Returns a (#data_points x #RK stages) matrix (250 x 500)\n",
    "        return dy\n",
    "    \n",
    "    def net_u0(self):\n",
    "        \n",
    "        u1 = self.net_u(self.x0)\n",
    "        u = u1[:,:-1]\n",
    "        \n",
    "        u_x  = self.forward_gradients(u, self.x0)\n",
    "        u_xx = self.forward_gradients(u_x, self.x0)\n",
    "        \n",
    "        \n",
    "        f = - u*u_x + (self.nu)*u_xx\n",
    "        \n",
    "        u0 = u1 - self.dt*torch.matmul(f,self.IRK_weights.T)\n",
    "        \n",
    "        return u0\n",
    "    \n",
    "    def net_u1(self):\n",
    "        return self.net_u(self.x1)\n",
    "    \n",
    "    def loss_f(self, u0, u0_pred):\n",
    "        return torch.mean(torch.square(u0-u0_pred)) + torch.mean(torch.square(self.net_u1()))\n",
    "    \n",
    "    def optimizer_step(self):\n",
    "        # Compute losses\n",
    "\n",
    "        # Zero the grads for the model paramters in the optimizer\n",
    "        self.optimizer.zero_grad()\n",
    "            \n",
    "        # Compute the losses and backpropagate the losses\n",
    "        loss = self.loss_f(self.u0, self.net_u0())\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer one iteration with the given optimizer\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def fit(self, epochs = 1):\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = self.optimizer_step()\n",
    "\n",
    "            if epoch % 100 == 99:\n",
    "                with torch.no_grad():\n",
    "                    valid_loss = torch.norm(test_u - pinn.predict(test_X)[:,-1], 2)/torch.norm(test_u, 2)\n",
    "                    print(f'Epoch {epoch+1}: Training Loss = {loss_value}, Validation Loss = {valid_loss.item()}')\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        return self.net_u(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn = PINN(dt, x0, u0, x1, lb, ub, IRK_weights, nu = (0.01/np.pi), layers = [1, 50, 50, 50, q+1], lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 0.38780128955841064, Validation Loss = 0.7980650067329407\n",
      "Epoch 200: Training Loss = 0.06589822471141815, Validation Loss = 0.6330591440200806\n",
      "Epoch 300: Training Loss = 0.049171850085258484, Validation Loss = 0.5695068836212158\n",
      "Epoch 400: Training Loss = 0.029959149658679962, Validation Loss = 0.5061505436897278\n",
      "Epoch 500: Training Loss = 0.01575472764670849, Validation Loss = 0.37142205238342285\n",
      "Epoch 600: Training Loss = 0.01085569430142641, Validation Loss = 0.2782757580280304\n",
      "Epoch 700: Training Loss = 0.008294481784105301, Validation Loss = 0.21886804699897766\n",
      "Epoch 800: Training Loss = 0.006762710865586996, Validation Loss = 0.18273207545280457\n",
      "Epoch 900: Training Loss = 0.0054414840415120125, Validation Loss = 0.15740396082401276\n",
      "Epoch 1000: Training Loss = 0.00444675050675869, Validation Loss = 0.14091873168945312\n",
      "Epoch 1100: Training Loss = 0.0036396037321537733, Validation Loss = 0.1250518411397934\n",
      "Epoch 1200: Training Loss = 0.003010532818734646, Validation Loss = 0.11273060739040375\n",
      "Epoch 1300: Training Loss = 0.0026777517050504684, Validation Loss = 0.10157536715269089\n",
      "Epoch 1400: Training Loss = 0.0020578077528625727, Validation Loss = 0.09374726563692093\n",
      "Epoch 1500: Training Loss = 0.0016755560645833611, Validation Loss = 0.08703280240297318\n",
      "Epoch 1600: Training Loss = 0.0013620794052258134, Validation Loss = 0.0776459127664566\n",
      "Epoch 1700: Training Loss = 0.001105596893467009, Validation Loss = 0.07734452188014984\n",
      "Epoch 1800: Training Loss = 0.0009182849898934364, Validation Loss = 0.07424292713403702\n",
      "Epoch 1900: Training Loss = 0.0007093832828104496, Validation Loss = 0.07147520780563354\n",
      "Epoch 2000: Training Loss = 0.000572669436223805, Validation Loss = 0.06662388145923615\n",
      "Epoch 2100: Training Loss = 0.0005562618025578558, Validation Loss = 0.06488161534070969\n",
      "Epoch 2200: Training Loss = 0.0003654109314084053, Validation Loss = 0.061755988746881485\n",
      "Epoch 2300: Training Loss = 0.00031866130302660167, Validation Loss = 0.050436943769454956\n",
      "Epoch 2400: Training Loss = 0.0002614242257550359, Validation Loss = 0.048468369990587234\n",
      "Epoch 2500: Training Loss = 0.0002130521461367607, Validation Loss = 0.0499543733894825\n",
      "Epoch 2600: Training Loss = 0.00019358958525117487, Validation Loss = 0.05050071328878403\n",
      "Epoch 2700: Training Loss = 0.00016674761718604714, Validation Loss = 0.05209506303071976\n",
      "Epoch 2800: Training Loss = 0.00037229651934467256, Validation Loss = 0.04835629090666771\n",
      "Epoch 2900: Training Loss = 0.00014449791342485696, Validation Loss = 0.04935873672366142\n",
      "Epoch 3000: Training Loss = 0.0002448747691232711, Validation Loss = 0.04136437922716141\n"
     ]
    }
   ],
   "source": [
    "pinn.fit(epochs = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04136437922716141\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "u1_pred = pinn.predict(test_X)\n",
    "\n",
    "valid_loss = torch.norm(test_u - u1_pred[:,-1], 2)/torch.norm(test_u, 2)\n",
    "print(f'Validation Loss: {valid_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43704483f194429c844f37e79151de18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "%matplotlib widget\n",
    "device = torch.device('cpu')\n",
    "\n",
    "plot_results_discrete_inference(x, t, x0.to(device).detach().numpy(), u0.to(device).detach().numpy(), u_exact,\n",
    "                                  test_X.to(device).detach().numpy(), u1_pred.to(device).detach().numpy(),\n",
    "                                    idx_t0, idx_t1, lb, ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
