{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "sys.path.append('utils_continuous')\n",
    "from utils_continuous import preprocess_data_continuous_identification, plot_results_continuous_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess it\n",
    "data_path = 'data/burgers_shock.mat'\n",
    "\n",
    "N = 2000\n",
    "noise = 0.5\n",
    "\n",
    "x, t, u_exact, X, T, lb, ub, train_X, train_u, test_X, test_u = preprocess_data_continuous_identification(data_path, N, noise)\n",
    "\n",
    "train_X = torch.tensor(train_X, dtype = torch.float, requires_grad = True, device = device)\n",
    "train_u = torch.tensor(train_u, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_X = torch.tensor(test_X, dtype = torch.float, requires_grad = True, device = device)\n",
    "test_u = torch.tensor(test_u, dtype = torch.float, requires_grad = True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, lb, ub):\n",
    "        super().__init__()\n",
    "        self.lb = torch.tensor(lb, dtype = torch.float, device = device)\n",
    "        self.ub = torch.tensor(ub, dtype = torch.float, device = device)\n",
    "        \n",
    "        # Layer module\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Make the neural network\n",
    "        input_dim = layers[0]\n",
    "        for output_dim in layers[1:]:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "            nn.init.xavier_normal_(self.layers[-1].weight)\n",
    "            input_dim = output_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.tanh(layer(x))\n",
    "\n",
    "        outputs = self.layers[-1](x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, X, u, lb, ub, nu, layers = [2, 20, 20, 20, 1], lr = 1e-2, device = torch.device('cpu')):\n",
    "        self.nu = nu\n",
    "        self.x_f = X[:, :1]\n",
    "        self.t_f = X[:, 1:]\n",
    "        self.u = u\n",
    "        \n",
    "        self.net_u = NeuralNet(layers, lb, ub)\n",
    "        self.net_u.to(device)\n",
    "        \n",
    "        # Physical paramters to optimize\n",
    "        self.lmbda = nn.ParameterList()\n",
    "        self.lmbda.append(nn.Parameter(0.0*torch.ones(1, device = device)))\n",
    "        self.lmbda.append(nn.Parameter(-6.0*torch.ones(1, device = device)))\n",
    "        \n",
    "        params = list(self.lmbda) + list(self.net_u.parameters())\n",
    "        self.optimizer = torch.optim.Adam(params, lr = lr, betas=(0.9, 0.999))\n",
    "    \n",
    "    def net_f(self):\n",
    "        \n",
    "        u = self.net_u(torch.cat([self.x_f, self.t_f],1))\n",
    "        \n",
    "        u_temp1 = torch.ones(self.x_f.size(), device = device)\n",
    "        u_temp2 = torch.ones(self.x_f.size(), device = device)\n",
    "        u_temp3 = torch.ones(self.x_f.size(), device = device)\n",
    "        \n",
    "        u_t = grad(u, self.t_f, grad_outputs = u_temp1, create_graph = True)[0]\n",
    "        u_x = grad(u, self.x_f, grad_outputs = u_temp2, create_graph = True)[0]\n",
    "        u_xx = grad(u_x, self.x_f, grad_outputs = u_temp3, create_graph = True)[0]\n",
    "\n",
    "        f = u_t + self.lmbda[0]*u*u_x - torch.exp(self.lmbda[1])*u_xx\n",
    "#         f = u_t + u*u_x - self.nu*u_xx\n",
    "    \n",
    "        del u_temp1\n",
    "        del u_temp2\n",
    "        del u_temp3\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    def loss_f(self, u, u_pred):\n",
    "        return torch.mean(torch.square(u-u_pred)) + torch.mean(torch.square(self.net_f()))\n",
    "    \n",
    "    def optimizer_step(self):\n",
    "        # Zero the grads for the model paramters in the optimizer\n",
    "        self.optimizer.zero_grad()\n",
    "            \n",
    "        # Compute the losses and backpropagate the losses\n",
    "        loss = self.loss_f(self.u, self.net_u(torch.cat([self.x_f, self.t_f],1)))\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer one iteration with the given optimizer\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def fit(self, epochs = 1):\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = self.optimizer_step()\n",
    "\n",
    "            if epoch % 100 == 99:\n",
    "                with torch.no_grad():\n",
    "                    valid_loss = torch.norm(test_u - pinn.predict(test_X), 2)/torch.norm(test_u, 2)\n",
    "                    print(f'Epoch {epoch+1}: Loss = {loss_value}, Valid Loss = {valid_loss.item()}')\n",
    "            if epoch % 1000 == 999:\n",
    "                print(f'Lambda 1 = {self.lmbda[0].item()}, Lambda 2 = {torch.exp(self.lmbda[1]).item()}\\n')\n",
    "                \n",
    "    def predict(self, test_X):\n",
    "        return self.net_u(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "pinn = PINN(train_X, train_u, lb, ub, nu = (0.01/np.pi), layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1], lr = 0.0003, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss = 0.34559741616249084, Valid Loss = 0.7840022444725037\n",
      "Epoch 200: Loss = 0.25578761100769043, Valid Loss = 0.621925413608551\n",
      "Epoch 300: Loss = 0.15509286522865295, Valid Loss = 0.360353022813797\n",
      "Epoch 400: Loss = 0.14149537682533264, Valid Loss = 0.3170502483844757\n",
      "Epoch 500: Loss = 0.13986119627952576, Valid Loss = 0.31121739745140076\n",
      "Epoch 600: Loss = 0.13840632140636444, Valid Loss = 0.3058587312698364\n",
      "Epoch 700: Loss = 0.1368308663368225, Valid Loss = 0.29983189702033997\n",
      "Epoch 800: Loss = 0.13507318496704102, Valid Loss = 0.292924702167511\n",
      "Epoch 900: Loss = 0.13313017785549164, Valid Loss = 0.2850228548049927\n",
      "Epoch 1000: Loss = 0.1310836374759674, Valid Loss = 0.2762320637702942\n",
      "Lambda 1 = 0.12217088043689728, Lambda 2 = 0.0030862162820994854\n",
      "\n",
      "Epoch 1100: Loss = 0.12909330427646637, Valid Loss = 0.2670291066169739\n",
      "Epoch 1200: Loss = 0.12721791863441467, Valid Loss = 0.25793105363845825\n",
      "Epoch 1300: Loss = 0.12537342309951782, Valid Loss = 0.2488793134689331\n",
      "Epoch 1400: Loss = 0.12354142963886261, Valid Loss = 0.23954227566719055\n",
      "Epoch 1500: Loss = 0.12171570211648941, Valid Loss = 0.22985801100730896\n",
      "Epoch 1600: Loss = 0.1198340579867363, Valid Loss = 0.21969148516654968\n",
      "Epoch 1700: Loss = 0.11792895942926407, Valid Loss = 0.20898129045963287\n",
      "Epoch 1800: Loss = 0.11608204245567322, Valid Loss = 0.198154479265213\n",
      "Epoch 1900: Loss = 0.11448149383068085, Valid Loss = 0.18779884278774261\n",
      "Epoch 2000: Loss = 0.11309950798749924, Valid Loss = 0.1782233864068985\n",
      "Lambda 1 = 0.40865179896354675, Lambda 2 = 0.0038417356554418802\n",
      "\n",
      "Epoch 2100: Loss = 0.11187352985143661, Valid Loss = 0.16930073499679565\n",
      "Epoch 2200: Loss = 0.11080706864595413, Valid Loss = 0.16110312938690186\n",
      "Epoch 2300: Loss = 0.1099977046251297, Valid Loss = 0.15345211327075958\n",
      "Epoch 2400: Loss = 0.1091754212975502, Valid Loss = 0.1468566507101059\n",
      "Epoch 2500: Loss = 0.10833295434713364, Valid Loss = 0.14072616398334503\n",
      "Epoch 2600: Loss = 0.10781426727771759, Valid Loss = 0.1351761370897293\n",
      "Epoch 2700: Loss = 0.10727156698703766, Valid Loss = 0.13026617467403412\n",
      "Epoch 2800: Loss = 0.10682874917984009, Valid Loss = 0.12574562430381775\n",
      "Epoch 2900: Loss = 0.10686910897493362, Valid Loss = 0.12171594053506851\n",
      "Epoch 3000: Loss = 0.1061234399676323, Valid Loss = 0.11823476105928421\n",
      "Lambda 1 = 0.6254361271858215, Lambda 2 = 0.004280619323253632\n",
      "\n",
      "Epoch 3100: Loss = 0.10586833953857422, Valid Loss = 0.11506932228803635\n",
      "Epoch 3200: Loss = 0.1055908277630806, Valid Loss = 0.11213501542806625\n",
      "Epoch 3300: Loss = 0.10539059340953827, Valid Loss = 0.10928332060575485\n",
      "Epoch 3400: Loss = 0.10521091520786285, Valid Loss = 0.10688243806362152\n",
      "Epoch 3500: Loss = 0.10508009791374207, Valid Loss = 0.10438494384288788\n",
      "Epoch 3600: Loss = 0.10477840900421143, Valid Loss = 0.10229158401489258\n",
      "Epoch 3700: Loss = 0.10464280098676682, Valid Loss = 0.10031376779079437\n",
      "Epoch 3800: Loss = 0.10446514189243317, Valid Loss = 0.09834308177232742\n",
      "Epoch 3900: Loss = 0.10450855642557144, Valid Loss = 0.09678994119167328\n",
      "Epoch 4000: Loss = 0.10418900847434998, Valid Loss = 0.09466911107301712\n",
      "Lambda 1 = 0.7201040387153625, Lambda 2 = 0.004453200846910477\n",
      "\n",
      "Epoch 4100: Loss = 0.10404293239116669, Valid Loss = 0.09324478358030319\n",
      "Epoch 4200: Loss = 0.1039591059088707, Valid Loss = 0.09155529737472534\n",
      "Epoch 4300: Loss = 0.1038183718919754, Valid Loss = 0.09011644870042801\n",
      "Epoch 4400: Loss = 0.10377737134695053, Valid Loss = 0.08850252628326416\n",
      "Epoch 4500: Loss = 0.10380826890468597, Valid Loss = 0.087531678378582\n",
      "Epoch 4600: Loss = 0.1034681424498558, Valid Loss = 0.08575599640607834\n",
      "Epoch 4700: Loss = 0.10340256989002228, Valid Loss = 0.08459708094596863\n",
      "Epoch 4800: Loss = 0.10355617851018906, Valid Loss = 0.08305118978023529\n",
      "Epoch 4900: Loss = 0.10335741192102432, Valid Loss = 0.08196797966957092\n",
      "Epoch 5000: Loss = 0.10341204702854156, Valid Loss = 0.08072849363088608\n",
      "Lambda 1 = 0.7759465575218201, Lambda 2 = 0.004556399770081043\n",
      "\n",
      "Epoch 5100: Loss = 0.10316061228513718, Valid Loss = 0.07999828457832336\n",
      "Epoch 5200: Loss = 0.1032581478357315, Valid Loss = 0.07911549508571625\n",
      "Epoch 5300: Loss = 0.10302042216062546, Valid Loss = 0.0774819627404213\n",
      "Epoch 5400: Loss = 0.10296052694320679, Valid Loss = 0.07684013992547989\n",
      "Epoch 5500: Loss = 0.10327135026454926, Valid Loss = 0.07629229128360748\n",
      "Epoch 5600: Loss = 0.10265934467315674, Valid Loss = 0.07459433376789093\n",
      "Epoch 5700: Loss = 0.10275188833475113, Valid Loss = 0.07397937029600143\n",
      "Epoch 5800: Loss = 0.10273969173431396, Valid Loss = 0.07317492365837097\n",
      "Epoch 5900: Loss = 0.10246837884187698, Valid Loss = 0.07205616682767868\n",
      "Epoch 6000: Loss = 0.1023973897099495, Valid Loss = 0.07117980718612671\n",
      "Lambda 1 = 0.8154968619346619, Lambda 2 = 0.004635666497051716\n",
      "\n",
      "Epoch 6100: Loss = 0.102383092045784, Valid Loss = 0.07043881714344025\n",
      "Epoch 6200: Loss = 0.10235224664211273, Valid Loss = 0.06944527477025986\n",
      "Epoch 6300: Loss = 0.10222690552473068, Valid Loss = 0.06874900311231613\n",
      "Epoch 6400: Loss = 0.10221771895885468, Valid Loss = 0.06818034499883652\n",
      "Epoch 6500: Loss = 0.10249354690313339, Valid Loss = 0.06735815852880478\n",
      "Epoch 6600: Loss = 0.10207108408212662, Valid Loss = 0.06663595885038376\n",
      "Epoch 6700: Loss = 0.10219506174325943, Valid Loss = 0.06645353138446808\n",
      "Epoch 6800: Loss = 0.10274600237607956, Valid Loss = 0.06559742242097855\n",
      "Epoch 6900: Loss = 0.1019810140132904, Valid Loss = 0.0650109127163887\n",
      "Epoch 7000: Loss = 0.10207017511129379, Valid Loss = 0.06461617350578308\n",
      "Lambda 1 = 0.8476741909980774, Lambda 2 = 0.004694389179348946\n",
      "\n",
      "Epoch 7100: Loss = 0.10210365802049637, Valid Loss = 0.06418339908123016\n",
      "Epoch 7200: Loss = 0.10185278952121735, Valid Loss = 0.06319019198417664\n",
      "Epoch 7300: Loss = 0.10183680802583694, Valid Loss = 0.06258753687143326\n",
      "Epoch 7400: Loss = 0.10219889134168625, Valid Loss = 0.06209074705839157\n",
      "Epoch 7500: Loss = 0.1020662933588028, Valid Loss = 0.0614372193813324\n",
      "Epoch 7600: Loss = 0.1018257588148117, Valid Loss = 0.060795485973358154\n",
      "Epoch 7700: Loss = 0.1017041802406311, Valid Loss = 0.060274526476860046\n",
      "Epoch 7800: Loss = 0.10163968801498413, Valid Loss = 0.05980106443166733\n",
      "Epoch 7900: Loss = 0.10159240663051605, Valid Loss = 0.05935518071055412\n",
      "Epoch 8000: Loss = 0.10155665129423141, Valid Loss = 0.0589185431599617\n",
      "Lambda 1 = 0.8750467300415039, Lambda 2 = 0.00472570164129138\n",
      "\n",
      "Epoch 8100: Loss = 0.10153274983167648, Valid Loss = 0.058489810675382614\n",
      "Epoch 8200: Loss = 0.1015268862247467, Valid Loss = 0.05807585269212723\n",
      "Epoch 8300: Loss = 0.1015625, Valid Loss = 0.057712338864803314\n",
      "Epoch 8400: Loss = 0.10168690234422684, Valid Loss = 0.0574599988758564\n",
      "Epoch 8500: Loss = 0.10178358852863312, Valid Loss = 0.05730612203478813\n",
      "Epoch 8600: Loss = 0.10145266354084015, Valid Loss = 0.05693165957927704\n",
      "Epoch 8700: Loss = 0.10135509818792343, Valid Loss = 0.056502483785152435\n",
      "Epoch 8800: Loss = 0.1015021800994873, Valid Loss = 0.05659643933176994\n",
      "Epoch 8900: Loss = 0.10160310566425323, Valid Loss = 0.056612275540828705\n",
      "Epoch 9000: Loss = 0.10129039734601974, Valid Loss = 0.055464860051870346\n",
      "Lambda 1 = 0.8960216045379639, Lambda 2 = 0.004737793002277613\n",
      "\n",
      "Epoch 9100: Loss = 0.10154462605714798, Valid Loss = 0.0552382729947567\n",
      "Epoch 9200: Loss = 0.10130015015602112, Valid Loss = 0.055144548416137695\n",
      "Epoch 9300: Loss = 0.10136261582374573, Valid Loss = 0.05504250153899193\n",
      "Epoch 9400: Loss = 0.10133787244558334, Valid Loss = 0.054955050349235535\n",
      "Epoch 9500: Loss = 0.10132129490375519, Valid Loss = 0.05406009778380394\n",
      "Epoch 9600: Loss = 0.10125631839036942, Valid Loss = 0.05418149754405022\n",
      "Epoch 9700: Loss = 0.10139065235853195, Valid Loss = 0.0543484129011631\n",
      "Epoch 9800: Loss = 0.10115814208984375, Valid Loss = 0.05359259247779846\n",
      "Epoch 9900: Loss = 0.10154076665639877, Valid Loss = 0.053582753986120224\n",
      "Epoch 10000: Loss = 0.10118266940116882, Valid Loss = 0.05325787141919136\n",
      "Lambda 1 = 0.9107542634010315, Lambda 2 = 0.004741805139929056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "pinn.fit(epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05325787141919136\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "u_pred = pinn.predict(test_X)\n",
    "valid_loss = torch.norm(test_u - pinn.predict(test_X), 2)/torch.norm(test_u, 2)\n",
    "print(valid_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f12c35b7229422b842c686663b3d087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "%matplotlib widget\n",
    "device = torch.device('cpu')\n",
    "\n",
    "plot_results_continuous_identification(x, t, X, T, u_exact, u_pred.to(device).detach().numpy(),\n",
    "                                  train_X.to(device).detach().numpy(), train_u.to(device).detach().numpy(),\n",
    "                                  test_X.to(device).detach().numpy(), pinn.lmbda[0].item(), torch.exp(pinn.lmbda[1]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
